import os
from typing import List
from swift.llm import InferEngine, InferRequest, PtEngine, RequestConfig
from swift.plugin import InferStats

# ============================
# 1. Audio-Reasoner Prompt
# ============================

system = """You are an audio deep-thinking model.
Upon receiving a question, please respond in two parts: <THINK> and <RESPONSE>.
The <THINK> section should be further divided into four parts:
<PLANNING>, <CAPTION>, <REASONING>, and <SUMMARY>.
"""

def get_message(audiopath, prompt):
    return [
        {"role": "system", "content": system},
        {
            "role": "user",
            "content": [
                {"type": "audio", "audio": audiopath},
                {"type": "text", "text": prompt}
            ]
        }
    ]

# ============================
# 2. Stream inference
# ============================

def infer_stream(engine: InferEngine, infer_request: InferRequest):
    request_config = RequestConfig(
        max_tokens=2048,
        temperature=0,
        stream=True
    )
    metric = InferStats()
    gen = engine.infer([infer_request], request_config, metrics=[metric])

    query = infer_request.messages[1]["content"][1]["text"]
    print(f"\nQuery: {query}\nResponse:\n")

    output = ""
    for resp_list in gen:
        if resp_list[0] is None:
            continue
        delta = resp_list[0].choices[0].delta.content
        print(delta, end="", flush=True)
        output += delta

    print("\n\nMetric:", metric.compute())
    return output


# ============================
# 3. Load Audio-Reasoner model
# ============================

# ğŸ”¥ ä½ çœŸæ­£çš„æ¨¡å‹è·¯å¾„ï¼ˆä½ å·²ç»ç»™è¿‡ï¼‰
MODEL_PATH = "/data/shixun/zhaohaozhe/model"

engine = PtEngine(
    MODEL_PATH,
    model_type="qwen2_audio",   # æ¥è‡ª config.json
    max_batch_size=1,           # Audio-Reasoner éå¸¸åƒæ˜¾å­˜ï¼Œå¿…é¡» 1
    trust_remote_code=True      # Qwen2Audio æ˜¯è‡ªå®šä¹‰æ¶æ„
)

# ============================
# 4. Audio-Reasoner API
# ============================

def audioreasoner_gen(audiopath, prompt):
    messages = get_message(audiopath, prompt)
    request = InferRequest(messages=messages)
    return infer_stream(engine, request)


# ============================
# 5. Main
# ============================

def main():
    # ä½ çš„æµ‹è¯•éŸ³é¢‘
    audiopath = "assets/test.wav"

    # Audio-Reasoner é£æ ¼é—®é¢˜
    prompt = "Which of the following best describes the rhythmic feel and time signature of the song?"

    audioreasoner_gen(audiopath, prompt)


if __name__ == "__main__":
    main()
